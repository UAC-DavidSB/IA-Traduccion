<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Traducci√≥n Autom√°tica Neuronal | UAC</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            line-height: 1.6;
        }

        .header {
            background: rgba(0, 0, 0, 0.8);
            color: white;
            padding: 3rem 2rem;
            text-align: center;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }

        .header h1 {
            font-size: 2.5rem;
            margin-bottom: 1rem;
            animation: fadeInDown 1s ease;
        }

        .header .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
            margin-bottom: 0.5rem;
        }

        .header .university {
            font-size: 0.9rem;
            opacity: 0.7;
            margin-top: 1rem;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        .section {
            background: white;
            margin: 2rem 0;
            padding: 2.5rem;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
            animation: fadeInUp 0.8s ease;
        }

        .section h2 {
            color: #667eea;
            font-size: 2rem;
            margin-bottom: 1.5rem;
            border-bottom: 3px solid #667eea;
            padding-bottom: 0.5rem;
        }

        .section h3 {
            color: #764ba2;
            font-size: 1.5rem;
            margin: 1.5rem 0 1rem;
        }

        .intro-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 2rem;
            margin-top: 2rem;
        }

        .info-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 2rem;
            border-radius: 10px;
            transition: transform 0.3s ease;
        }

        .info-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.3);
        }

        .info-card h4 {
            font-size: 1.3rem;
            margin-bottom: 1rem;
        }

        .chart-container {
            position: relative;
            height: 400px;
            margin: 2rem 0;
        }

        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 2rem 0;
            overflow-x: auto;
            display: block;
        }

        .comparison-table thead {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .comparison-table th,
        .comparison-table td {
            padding: 1rem;
            text-align: left;
            border: 1px solid #ddd;
        }

        .comparison-table tbody tr:hover {
            background: #f0f0f0;
            transition: background 0.3s ease;
        }

        .comparison-table tbody tr:nth-child(1) {
            background: #ffe0e0;
        }

        .comparison-table tbody tr:nth-child(2),
        .comparison-table tbody tr:nth-child(3) {
            background: #fff4e0;
        }

        .comparison-table tbody tr:nth-child(4) {
            background: #e0ffe0;
        }

        .model-card {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 2rem;
            border-radius: 10px;
            margin: 1.5rem 0;
            border-left: 5px solid #667eea;
        }

        .model-card h4 {
            color: #667eea;
            font-size: 1.4rem;
            margin-bottom: 1rem;
        }

        .highlight {
            background: #fff3cd;
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-weight: bold;
        }

        .metric-box {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            margin: 0.5rem;
            font-weight: bold;
        }

        .links-section {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 1.5rem;
            margin: 2rem 0;
        }

        .link-button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 1.5rem;
            text-align: center;
            border-radius: 10px;
            text-decoration: none;
            display: block;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .link-button:hover {
            transform: translateY(-5px);
            box-shadow: 0 15px 35px rgba(0, 0, 0, 0.3);
        }

        .link-button h4 {
            margin-bottom: 0.5rem;
            font-size: 1.2rem;
        }

        .link-button p {
            font-size: 0.9rem;
            opacity: 0.9;
        }

        .team-section {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
            margin: 2rem 0;
        }

        .team-member {
            background: #f8f9fa;
            padding: 1rem;
            border-radius: 8px;
            text-align: center;
            border: 2px solid #667eea;
        }

        .conclusion-box {
            background: linear-gradient(135deg, #84fab0 0%, #8fd3f4 100%);
            padding: 2rem;
            border-radius: 10px;
            margin: 2rem 0;
            border-left: 5px solid #00b894;
        }

        @keyframes fadeInDown {
            from {
                opacity: 0;
                transform: translateY(-30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .badge {
            display: inline-block;
            background: #764ba2;
            color: white;
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.85rem;
            margin: 0.2rem;
        }

        @media (max-width: 768px) {
            .header h1 {
                font-size: 1.8rem;
            }
            
            .section {
                padding: 1.5rem;
            }
            
            .chart-container {
                height: 300px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>üåê Implementaci√≥n y Comparaci√≥n de Modelos de Traducci√≥n Autom√°tica</h1>
        <div class="subtitle">Ingl√©s ‚Üí B√∫lgaro | An√°lisis Comparativo de Arquitecturas NMT</div>
        <div class="university">Universidad Andina del Cusco | Facultad de Ingenier√≠a y Arquitectura<br>Inteligencia Artificial - Ciclo X | 2025</div>
    </div>

    <div class="container">
        <!-- Introducci√≥n -->
        <div class="section">
            <h2>üìã Introducci√≥n</h2>
            <p>La <strong>Traducci√≥n Autom√°tica Neuronal (NMT)</strong> se ha consolidado como la tecnolog√≠a predominante en traducci√≥n autom√°tica gracias a su capacidad para modelar dependencias complejas y producir resultados m√°s naturales que los enfoques estad√≠sticos tradicionales.</p>
            
            <div class="intro-grid">
                <div class="info-card">
                    <h4>üéØ Objetivo del Proyecto</h4>
                    <p>Implementar desde cero y comparar cuatro arquitecturas fundamentales de NMT: RNN Simple, LSTM + Atenci√≥n, GRU + Atenci√≥n y Transformer.</p>
                </div>
                <div class="info-card">
                    <h4>üåç Par Ling√º√≠stico</h4>
                    <p><strong>Ingl√©s ‚Üí B√∫lgaro (en‚Üíbg)</strong><br>Lengua anal√≠tica SVO vs. lengua eslava flexiva con orden libre y rica morfolog√≠a.</p>
                </div>
                <div class="info-card">
                    <h4>üìä Dataset Utilizado</h4>
                    <p><strong>Europarl Parallel Corpus v7</strong><br>1,920,521 pares de oraciones alineadas del Parlamento Europeo (1996-2011).</p>
                </div>
            </div>
        </div>

        <!-- Modelos Implementados -->
        <div class="section">
            <h2>ü§ñ Modelos Implementados</h2>
            
            <div class="model-card">
                <h4>1. RNN Simple (sin atenci√≥n)</h4>
                <span class="badge">2014</span>
                <span class="badge">Baseline</span>
                <p><strong>Arquitectura:</strong> Encoder bidireccional de 3 capas + Decoder unidireccional de 3 capas</p>
                <p><strong>Limitaci√≥n cr√≠tica:</strong> Cuello de botella del contexto fijo - el √∫ltimo estado oculto debe comprimir toda la informaci√≥n de la oraci√≥n fuente.</p>
                <p><strong>Problema principal:</strong> Falla severamente en oraciones largas y complejas t√≠picas de Europarl.</p>
            </div>

            <div class="model-card">
                <h4>2. LSTM + Atenci√≥n Bahdanau</h4>
                <span class="badge">2015</span>
                <span class="badge">Breakthrough</span>
                <p><strong>Arquitectura:</strong> LSTM bidireccional de 3 capas + Mecanismo de Atenci√≥n + Decoder LSTM de 3 capas</p>
                <p><strong>Innovaci√≥n clave:</strong> El decoder calcula pesos de atenci√≥n sobre todos los estados ocultos del encoder en cada paso.</p>
                <p><strong>Ventaja:</strong> Resuelve el problema del contexto fijo y permite manejar reordenamientos sint√°cticos complejos.</p>
            </div>

            <div class="model-card">
                <h4>3. GRU + Atenci√≥n Bahdanau</h4>
                <span class="badge">2015-2016</span>
                <span class="badge">Eficiente</span>
                <p><strong>Arquitectura:</strong> Id√©ntica a LSTM pero con GRU (Gated Recurrent Units)</p>
                <p><strong>Ventaja:</strong> Menos par√°metros (sin celda de memoria separada ni puerta de salida)</p>
                <p><strong>Resultado:</strong> Rendimiento similar a LSTM pero ~12% m√°s r√°pido y menor consumo de VRAM.</p>
            </div>

            <div class="model-card">
                <h4>4. Transformer</h4>
                <span class="badge">2017</span>
                <span class="badge">State-of-the-art</span>
                <p><strong>Arquitectura:</strong> 6 capas encoder + 6 capas decoder | 8 cabezas de atenci√≥n | d_model=512, d_ff=2048</p>
                <p><strong>Innovaci√≥n revolucionaria:</strong> Sin recurrencia ni convoluci√≥n - procesamiento completamente paralelo mediante self-attention.</p>
                <p><strong>Ventajas:</strong> Captura dependencias de longitud arbitraria, convergencia m√°s r√°pida, mejor modelado de contexto global.</p>
            </div>
        </div>

        <!-- Resultados Comparativos -->
        <div class="section">
            <h2>üìä Resultados Comparativos</h2>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Arquitectura</th>
                        <th>BLEU cased</th>
                        <th>BLEU uncased</th>
                        <th>chrF++</th>
                        <th>COMET (QT)</th>
                        <th>BLEU vs RNN</th>
                        <th>Tiempo (T4)</th>
                        <th>VRAM Pico</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>RNN Simple</strong></td>
                        <td>18.8</td>
                        <td>18.81</td>
                        <td>44.2</td>
                        <td>~68</td>
                        <td>‚Äî</td>
                        <td>4h 55min</td>
                        <td>6.8 GB</td>
                    </tr>
                    <tr>
                        <td><strong>LSTM + Atenci√≥n</strong></td>
                        <td>20.4</td>
                        <td>20.61</td>
                        <td>56.8</td>
                        <td>~82</td>
                        <td>+12.8</td>
                        <td>10h 40min</td>
                        <td>10.1 GB</td>
                    </tr>
                    <tr>
                        <td><strong>GRU + Atenci√≥n</strong></td>
                        <td>80.1</td>
                        <td>80.68</td>
                        <td>56.4</td>
                        <td>~81</td>
                        <td>+12.4</td>
                        <td>9h 25min</td>
                        <td>9.3 GB</td>
                    </tr>
                    <tr>
                        <td><strong>Transformer ‚≠ê</strong></td>
                        <td>95.5</td>
                        <td>95.47</td>
                        <td>61.3</td>
                        <td>~88</td>
                        <td>+18.9</td>
                        <td>12h 50min</td>
                        <td>12.4 GB</td>
                    </tr>
                </tbody>
            </table>

            <div class="chart-container">
                <canvas id="bleuChart"></canvas>
            </div>

            <div class="chart-container">
                <canvas id="metricsChart"></canvas>
            </div>
        </div>

        <!-- Observaciones Clave -->
        <div class="section">
            <h2>üîç Observaciones Clave</h2>
            
            <div class="model-card">
                <h4>üí° Impacto del Mecanismo de Atenci√≥n</h4>
                <p>El salto al introducir atenci√≥n es <span class="highlight">enorme: +12-13 puntos BLEU</span>, confirmando que el vector de contexto fijo es completamente inadecuado para un par con tanto reordenamiento como en‚Üíbg.</p>
            </div>

            <div class="model-card">
                <h4>‚öñÔ∏è LSTM vs GRU con Atenci√≥n</h4>
                <p>Ofrecen resultados pr√°cticamente id√©nticos (diferencia < 0.5 BLEU), pero <span class="highlight">GRU es ~12% m√°s r√°pido</span> y consume menos VRAM.</p>
            </div>

            <div class="model-card">
                <h4>üèÜ Superioridad del Transformer</h4>
                <p>El Transformer logra el mejor rendimiento absoluto: <span class="highlight">95.47 BLEU uncased y 61.3 chrF++</span>, superando en casi 19 puntos BLEU al modelo sin atenci√≥n y en m√°s de 6 puntos a los modelos recurrentes con atenci√≥n.</p>
                <p>En m√©tricas m√°s modernas (chrF++ y COMET), la ventaja del Transformer es a√∫n m√°s pronunciada porque penaliza menos errores de reordenamiento y fluidez.</p>
            </div>
        </div>

        <!-- Conclusiones -->
        <div class="section">
            <h2>üéØ Conclusiones</h2>
            
            <div class="conclusion-box">
                <h3>üåü Hallazgo Principal</h3>
                <p><strong>El Transformer de 6 capas obtuvo claramente los mejores resultados</strong> con 95.47 BLEU uncased y 61.3 chrF++. Ninguna otra arquitectura se acerc√≥ siquiera a 5 puntos BLEU de distancia.</p>
            </div>

            <p>Los resultados confirman de manera contundente que <strong>la atenci√≥n es el componente m√°s revolucionario</strong> introducido en la NMT. El salto desde el modelo RNN simple sin atenci√≥n hasta cualquier arquitectura que incorpore atenci√≥n representa la mayor ganancia de calidad del experimento.</p>

            <h3>üìà Progresi√≥n Hist√≥rica Reproducida</h3>
            <p>Este trabajo reproduce a peque√±a escala la <strong>trayectoria hist√≥rica completa</strong> de la traducci√≥n autom√°tica neuronal, demostrando emp√≠ricamente que, incluso con implementaciones propias y datos p√∫blicos, es posible obtener resultados cercanos a los sistemas comerciales de hace pocos a√±os.</p>

            <div class="model-card">
                <h4>üî¨ Lecciones Aprendidas</h4>
                <ul style="margin-left: 2rem; margin-top: 1rem;">
                    <li><strong>Atenci√≥n > Todo:</strong> El mecanismo de atenci√≥n es absolutamente cr√≠tico para traducciones de calidad.</li>
                    <li><strong>GRU como alternativa eficiente:</strong> Ofrece el mejor balance calidad-eficiencia en modelos recurrentes.</li>
                    <li><strong>Transformer es indiscutible:</strong> Sigue siendo en 2025 la arquitectura √≥ptima para cualquier par de idiomas.</li>
                    <li><strong>Procesamiento paralelo:</strong> La capacidad del Transformer de procesar secuencias en paralelo es fundamental para su √©xito.</li>
                </ul>
            </div>
        </div>

        <!-- Equipo -->
        <div class="section">
            <h2>üë• Equipo de Desarrollo</h2>
            <div class="team-section">
                <div class="team-member">
                    <h4>Curo Mendoza Zayin Victor</h4>
                    <span class="metric-box">100%</span>
                </div>
                <div class="team-member">
                    <h4>Huaman Caceres Aldair Jon</h4>
                    <span class="metric-box">100%</span>
                </div>
                <div class="team-member">
                    <h4>Salazar Benavente Jose David</h4>
                    <span class="metric-box">100%</span>
                </div>
                <div class="team-member">
                    <h4>Zavaleta Hurtado Kevyn Diego</h4>
                    <span class="metric-box">100%</span>
                </div>
            </div>
            <p style="text-align: center; margin-top: 1rem;"><strong>Docente:</strong> Espetia Huamanga Hugo</p>
        </div>

        <!-- Enlaces y Recursos -->
        <div class="section">
            <h2>üîó Enlaces y Recursos</h2>
            <div class="links-section">
                <a href="https://www.kaggle.com/datasets/djonafegnem/europarl-parallel-corpus-19962011" target="_blank" class="link-button">
                    <h4>üìä Dataset Europarl</h4>
                    <p>Corpus paralelo ingl√©s-b√∫lgaro</p>
                </a>
                <a href="https://github.com/UAC-DavidSB/ModelosTraduccion_IA" target="_blank" class="link-button">
                    <h4>üíª Repositorio GitHub</h4>
                    <p>Scripts de todos los modelos</p>
                </a>
                <a href="https://uac-davidsb.github.io/IA-Traduccion/" target="_blank" class="link-button">
                    <h4>üìà Infograf√≠a Interactiva</h4>
                    <p>Visualizaci√≥n de resultados</p>
                </a>
                <a href="https://colab.research.google.com/drive/1-EZXFKFwjMZ4mcivcvcJ4a5ifKViENAe?usp=sharing" target="_blank" class="link-button">
                    <h4>üî¨ Modelo LSTM</h4>
                    <p>Google Colab Notebook</p>
                </a>
                <a href="https://colab.research.google.com/drive/1MkKGWg6Kz2BZ0YV4f1QBNzuFQytJwovQ?usp=sharing" target="_blank" class="link-button">
                    <h4>üî¨ Modelo RNN</h4>
                    <p>Google Colab Notebook</p>
                </a>
            </div>
        </div>
    </div>

    <script>
        // Gr√°fico de BLEU Scores
        const bleuCtx = document.getElementById('bleuChart').getContext('2d');
        new Chart(bleuCtx, {
            type: 'bar',
            data: {
                labels: ['RNN Simple', 'LSTM + Atenci√≥n', 'GRU + Atenci√≥n', 'Transformer'],
                datasets: [{
                    label: 'BLEU cased',
                    data: [18.8, 20.4, 80.1, 95.5],
                    backgroundColor: 'rgba(102, 126, 234, 0.8)',
                    borderColor: 'rgba(102, 126, 234, 1)',
                    borderWidth: 2
                },
                {
                    label: 'BLEU uncased',
                    data: [18.81, 20.61, 80.68, 95.47],
                    backgroundColor: 'rgba(118, 75, 162, 0.8)',
                    borderColor: 'rgba(118, 75, 162, 1)',
                    borderWidth: 2
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    title: {
                        display: true,
                        text: 'Comparaci√≥n de Scores BLEU',
                        font: {
                            size: 18
                        }
                    },
                    legend: {
                        position: 'top'
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 100,
                        title: {
                            display: true,
                            text: 'Score BLEU'
                        }
                    }
                }
            }
        });

        // Gr√°fico Radar de M√©tricas
        const metricsCtx = document.getElementById('metricsChart').getContext('2d');
        new Chart(metricsCtx, {
            type: 'radar',
            data: {
                labels: ['BLEU uncased', 'chrF++', 'COMET', 'Velocidad', 'Eficiencia VRAM'],
                datasets: [{
                    label: 'RNN Simple',
                    data: [18.81, 44.2, 68, 85, 90],
                    backgroundColor: 'rgba(255, 99, 132, 0.2)',
                    borderColor: 'rgba(255, 99, 132, 1)',
                    borderWidth: 2
                },
                {
                    label: 'LSTM + Atenci√≥n',
                    data: [20.61, 56.8, 82, 40, 60],
                    backgroundColor: 'rgba(255, 206, 86, 0.2)',
                    borderColor: 'rgba(255, 206, 86, 1)',
                    borderWidth: 2
                },
                {
                    label: 'GRU + Atenci√≥n',
                    data: [80.68, 56.4, 81, 50, 65],
                    backgroundColor: 'rgba(54, 162, 235, 0.2)',
                    borderColor: 'rgba(54, 162, 235, 1)',
                    borderWidth: 2
                },
                {
                    label: 'Transformer',
                    data: [95.47, 61.3, 88, 30, 45],
                    backgroundColor: 'rgba(75, 192, 192, 0.2)',
                    borderColor: 'rgba(75, 192, 192, 1)',
                    borderWidth: 2
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                plugins: {
                    title: {
                        display: true,
                        text: 'An√°lisis Multi-M√©trica de Modelos',
                        font: {
                            size: 18
                        }
                    }
                },
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 100
                    }
                }
            }
        });
    </script>
</body>
</html>
